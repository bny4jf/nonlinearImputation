\documentclass[compress,mathserif]{beamer}
\usepackage[latin2]{inputenc}
%\usepackage[absolute]{textpos}
%\documentclass[handout,compress,mathserif]{beamer}
%\setbeameroption{show notes}

% This file is a solution template for:

% - Talk at a conference/colloquium.
% - Talk length is about 20min.
% - Style is ornate.



% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice.


\mode<presentation>
{
  \usetheme{frankfurt}
  % or ...
  \usecolortheme{UNR}
  \setbeamercovered{invisible}
  % or whatever (possibly just delete it)
}


\usepackage[USenglish]{babel}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{ifthen,array}
\usepackage{framed, color}
\usepackage{dsfont}
\usepackage{multirow}

\pretolerance5000 \hyphenpenalty9999
%\setlength{\TPHorizModule}{0.5cm} \setlength{\TPVertModule}{0.5cm}
%\textblockorigin{20mm}{20mm} % start everything near the top-left corner

\newcounter{ora}
\newcounter{perc}
\newcounter{kezdoora}
\newcounter{kezdoperc}
\newcounter{percek}
\setcounter{percek}{15}
\setcounter{kezdoora}{4} % for 1.35pm as the starting time

\providecommand{\leadingzero}[1]{\ifthenelse{\value{#1}<10}{0\arabic{#1}}{\arabic{#1}}}
\providecommand{\oradisplay}[1]{\ifthenelse{\value{#1}<60}{\arabic{kezdoora}:\leadingzero{#1}}{\setcounter{perc}{\value{#1}}\addtocounter{perc}{-60}\setcounter{ora}{\value{kezdoora}}\addtocounter{ora}{1}\arabic{ora}:\leadingzero{perc}}}

\definecolor{shadecolor}{rgb}{0.95,0.95,0.75}

\providecommand{\notes}[1]{{\tiny\textbf{Note:} #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Hasznos matek makrok
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\ind}{\mathds{1}}
\newcommand{\QED}{{}\hfill$\Box$}
\newcommand{\intl}[4]{\int_{#1}^{#2} \! {#3} \, \mathrm d{#4}}
\newcommand{\period}{\text{.}} % Ez azert kell, mert a matek . mashogy nez ki, mint a szovege.
\newcommand{\comma}{\text{,}}  % Ez azert kell, mert a matek , mashogy nez ki, mint a szovege.
\newcommand{\dist}{\,\mathop{\operatorname{\sim\,}}\limits}
\newcommand{\D}{\,\mathop{\operatorname{d}}\!}
%\newcommand{\E}{\mathop{\operatorname{E}}\nolimits}
\newcommand{\Lag}{\mathop{\operatorname{L}}}
\newcommand{\plim}{\mathop{\operatorname{plim}}\limits_{T\to\infty}\,}
\newcommand{\CES}[3]{\mathop{\operatorname{CES}}\left(\left\{#1\right\},\left\{#2\right\},#3\right)}
\newcommand{\cestwo}[5]{\left[#1^\frac1{#5}\,#2^\frac{#5-1}{#5}+#3^\frac1{#5}\,#4^\frac{#5-1}{#5}\right]^\frac{#5}{#5-1}}
\newcommand{\cesmore}[4]{\left[\sum_{#3}#1_{#3}^\frac1{#4}\,{#2}_{#3}^\frac{#4-1}{#4}\right]^\frac{#4}{#4-1}}
\newcommand{\cesPtwo}[5]{\left[#1\,#2^{1-#5}+#3\,#4^{1-#5}\right]^\frac{1}{1-#5}}
\newcommand{\cesPmore}[4]{\left[\sum_{#3}#1_{#3}\,#2_{#3}^{1-#4}\right]^\frac{1}{1-#4}}
\newcommand{\diff}[2]{\frac{\D #1}{\D #2}}
\newcommand{\pdiff}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\convex}[2]{\lambda #1 + (1-\lambda)#2}
\newcommand{\ABS}[1]{\left| #1 \right|}
\newcommand{\suchthat}{:\hskip1em}
\newcommand{\dispfrac}[2]{\frac{\displaystyle #1}{\displaystyle #2}} % Emeletes tortekhez hasznos.

\newcommand{\diag}{\mathop{\mathrm{diag\mathstrut}}}
\newcommand{\tr}{\mathop{\mathrm{tr\mathstrut}}}
\newcommand{\E}{\mathop{\mathrm{E\mathstrut}}}
\newcommand{\Var}{\mathop{\mathrm{Var\mathstrut}}\nolimits}
\newcommand{\Cov}{\mathop{\mathrm{Cov\mathstrut}}}
\newcommand{\sgn}{\mathop{\operatorname{sgn\mathstrut}}}

\newcommand{\covmat}{\mathbf\Sigma}
\newcommand{\ones}{\mathbf 1}
\newcommand{\zeros}{\mathbf 0}
\newcommand{\BAR}[1]{\overline{#1}}

\renewcommand{\time}[1]{\addtocounter{percek}{#1}}

\newlength{\tempsep}

\newenvironment{subeqs}{\setlength{\tempsep}{\arraycolsep}
\setlength{\arraycolsep}{0.13889em} % Ez azert kell, hogy ne hagyjon tul sok helyet az = korul.
\begin{subequations}\begin{eqnarray}}
{\end{eqnarray}\end{subequations}
\setlength{\arraycolsep}{\tempsep}}

\newenvironment{tapad}{\setlength{\tempsep}{\arraycolsep}
\setlength{\arraycolsep}{0.13889em}} % Ez azert kell, hogy ne hagyjon tul sok helyet az = korul.
{\setlength{\arraycolsep}{\tempsep}}

\newenvironment{eqnarr}{\setlength{\tempsep}{\arraycolsep}
\setlength{\arraycolsep}{0.13889em} % Ez azert kell, hogy ne hagyjon tul sok helyet az = korul.
\begin{eqnarray}}
{\end{eqnarray} \setlength{\arraycolsep}{\tempsep}}

\newenvironment{eqnarr*}{\setlength{\tempsep}{\arraycolsep}
\setlength{\arraycolsep}{0.13889em} % Ez azert kell, hogy ne hagyjon tul sok helyet az = korul.
\begin{eqnarray*}}
{\end{eqnarray*} \setlength{\arraycolsep}{\tempsep}}


%\usepackage[active]{srcltx} % SRC Specials: DVI [Inverse] Search
% Fuzz --- -------------------------------------------------------
\hfuzz5pt % Don't bother to report over-full boxes < 5pt
\vfuzz5pt % Don't bother to report over-full boxes < 5pt
% THEOREMS -------------------------------------------------------
% MATH -----------------------------------------------------------
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\Real}{\mathbb R}
\newcommand{\eps}{\varepsilon}
\newcommand{\To}{\longrightarrow}
\newcommand{\BX}{\mathbf{B}(X)}
\newcommand{\A}{\mathcal{A}}
\newcommand{\argmax}{\mathop{\operatorname{argmax}}\limits}
\newcommand{\argmin}{\mathop{\operatorname{argmin}}\limits}



\newcommand{\directory}{figures}
\newcommand*{\newtitle}{\egroup\begin{frame}\frametitle}

\newcommand{\fullpagefigure}[2]{\begin{frame}\frametitle{\hyperlink{#1back}{#2}}\hypertarget{#1}{{\begin{center}\includegraphics[height=0.9\textheight]{\directory/#1}\end{center}}}\end{frame}}
\newcommand{\widefigure}[2]{\begin{frame}\frametitle{\hyperlink{#1back}{#2}}\hypertarget{#1}{{\begin{center}\includegraphics[width=\linewidth]{\directory/#1}\end{center}}}\end{frame}}
\newcommand{\longfigure}[2]{\begin{frame}\frametitle{\hyperlink{#1back}{#2}}\hypertarget{#1}{{\begin{center}\includegraphics[height=0.8\textheight]{\directory/#1}\end{center}}}\end{frame}}
%\newcommand{\fullpagefigure}[2]{\begin{frame}\frametitle{\hyperlink{#1back}{#2}}\hypertarget{#1}{{\begin{centering}$#1$\end{centering}}}\end{frame}}
\newcommand{\answer}[1]{\begin{itemize}\item #1\end{itemize}}


\newcommand{\jumpto}[2]{\hypertarget{#1back}{\hyperlink{#1}{#2}}}
\newcommand{\backto}[2]{\hypertarget{#1}{\hyperlink{#1back}{#2}}}


\title{Imputation in GMM models with nonparametric missingness structure}

\author{Jason Abrevaya and Peter Toth
}
\institute{University of Texas at Austin, University of Nevada, Reno}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\date % (optional, should be abbreviation of conference name)
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

%\subject{Theoretical Computer Science}
% This is only inserted into the PDF information catalog. Can be left
% out.



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

\pgfdeclareimage[height=0.5cm]{university-logo}{LogoUNR.png}
\logo{\pgfuseimage{university-logo}}

\titlegraphic{\includegraphics[width=2.3cm]{LogoUNR}}
	
% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSection[]
{
  \begin{frame}[plain]
    \frametitle{\color{red}\insertsection}
    \addtocounter{framenumber}{-1}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}

\setbeamertemplate{navigation symbols}{}
%\setbeamertemplate{footline}{{}\hfill\insertframenumber}

\begin{document}

\begin{frame}[plain]
  \titlepage
    \addtocounter{framenumber}{-1}
\end{frame}






\section{Introduction}\hypertarget{Introduction}{}


\begin{frame}\frametitle{Imputation}\hypertarget{Imputation}{}
\begin{itemize}
\item We examine the case when the researcher
\begin{itemize}
\item has 1 variable ($X$) with large number of missing values (\~20\%)

\item fully observed variables ($\mathbf{Z}$)

\item wants to infer the relationship between a LHS variable $Y$ and the RHS variables $\mathbf{Z}$
\end{itemize}

\begin{enumerate}
\item learn the relationship between $X$ and $\mathbf{Z}$ using the fully observed cases
\item recover some of the variation in $X$ for the missing observations
\item using the augmented data to infer the relationship between $\mathbf{Z}$ and $Y$
\end{enumerate}

\item Chamberlain (1982), Abrevaya and Donald (2017), Murris (2019), Coe (2019)
\begin{itemize}
\item works well in linear models


\end{itemize}

\end{itemize}
\end{frame}



\begin{frame}\frametitle{Question}\hypertarget{Question}{}
\begin{itemize}
\item Abrevaya and Donald (2017) offers a simple GMM solution for the case when we have
\begin{itemize}
\item a linear model for $E[Y|X,\mathbf{Z}]$

\item another linear model connecting $X$ and $\mathbf{Z}$

\item the sole exlusion restriction that the missingness is (mean-)independent of $X$, conditional on $\mathbf{Z}$
\end{itemize}

\item Our question is: Is it possible to apply the framework for the case of
\begin{itemize}
\item parametric nonlinear model for $E[Y|X,\mathbf{Z}]$,
\item no assumption on the relationship between $X$ and $\mathbf{Z}$, other than $X$ is not independent of $\mathbf{Z}$,
\item arbitrary missingness structure with the same exclusion restriction as in the linear case
\end{itemize}

\item We aim to preserve the (relatively) simple nature of the GMM-framework


\end{itemize}
\end{frame}



\begin{frame}\frametitle{Today's results}\hypertarget{Today's results}{}
\begin{itemize}
\item We provide a GMM estimator that allows for efficiency gains IF the dimension of the $\mathbf{Z}$ is at most 4  (including the constant)
\begin{itemize}
\item you can have additional dimensions with discrete variables
\end{itemize}

\item We derive the asmyptotic properties of the estimator

\item Highlight the trade-offs:
\begin{itemize}
\item you do not want to do an imputation scheme if the estimates for the missing elements you use are very noisy

\item you have to do complicated schemes (including all $\mathbf{Z}$-s) if you do not allow for strict exclusion restrictions 


\end{itemize}

\end{itemize}
\end{frame}



\begin{frame}\frametitle{The model}\hypertarget{The model}{}
\begin{align*}
   E[Y|X,\mathbf{Z},M]= E[Y|X,\mathbf{Z}] & = h(\alpha X+\beta \mathbf{Z})\\
    f_{X|\mathbf{Z}, M}(x,z,m)&= f_{X|\mathbf{Z}}(x,z)
\end{align*}
\begin{itemize}
\item We know $h$, but the conditional distribution $f_{X|\mathbf{Z}}$ is unknown
\begin{itemize}
\item $h$ is smooth and well-behaved for identification (i.e. strictly increasing)
\end{itemize}

\item $M$ is the missingness indicator, taking the value 1 when the observation is missing (otherwise 0)

\item We observe
\[M, \mathbf{Z}, M\cdot X, Y
\]


\end{itemize}
\end{frame}



\begin{frame}\frametitle{Weakened exclusion restriction}\hypertarget{Weakened exclusion restriction}{}
\begin{itemize}
\item Directly from AD (2017)

\item Weaker than the missingness-at-random assumption (standard), as it is allowed for $M$ to depend on $\mathbf{Z}$

\item Roughly translates to $M \perp X$

\item Our two assumptions imply that
\[E(Y| \mathbf{Z}, M)= \int h(\alpha X+\beta \mathbf{Z})  f_{X|\mathbf{Z}}(x,\mathbf{Z}) dx
\]


\end{itemize}
\end{frame}







\section{Estimator and asymptotic theory}\hypertarget{Estimator and asymptotic theory}{}


\begin{frame}\frametitle{Population moments}\hypertarget{Population moments}{}
\begin{itemize}
\item Let us have $\mathbb{Z} \in \mathbb{R}^k$ (further, I will not emphasize that $\mathbf{Z}$ is a vector)
\begin{align*}
    E[g(\alpha,\beta; E[y|z])]=E\left[\begin{array}{c}
        (1-m) x(y- h(\alpha x + \beta z))  \\
        (1-m) z(y- h(\alpha x + \beta z)) \\
          m z(y- E[y|z])
    \end{array}\right]=0,
\end{align*}

\item Here $g$ is a function whose co-domain is $\mathbb{R}^{1+k+k}$
\begin{itemize}
\item the first $k+1$ moments are the basis of the usual GMM estimator (assumed to be well-behaved)

\item the argument $E[y|z]$ is the function of $z$ itself (technically a parameter) with the true value
\end{itemize}

\[E[y|z] = \int h(\alpha x + \beta z) f_{X|Z}(x,z) dx
\]


\end{itemize}
\end{frame}



\begin{frame}\frametitle{The imputation estimator (GMM)}\hypertarget{The imputation estimator (GMM)}{}
\begin{itemize}
\item We take the sample analogue of the population moments
\begin{align*}
    \hat{g}(a,b; \hat{E}[y|z])&=n^{-1}\sum_{i=1}^n\left[\begin{array}{c}
        (1-m_i) x_i(y_i- h(ax_i+bz_i))  \\
        (1-m_i) z_i(y_i- h(ax_i+bz_i)) \\
          m_i z_i(y_i- \hat{E}[y_i|z_i])
    \end{array}\right] \\
    \hat{E}[y_i|z_i]&= \int h(a x+b z_i) \hat{f}_{x|z}(x,z_i)dx
\end{align*}

\item $\hat{f}_{x|z}$ is a linear estimator of the conditional pdf $f_{x|z}$ (Nadaraya-Watson for us)
\[[\hat{\alpha}, \hat{\beta}] = \argmin_{a,b} \hat{g}(a,b;\hat{E}[y|z])'\hat{W}\hat{g}(a,b;\hat{E}[y|z])
\]


\end{itemize}
\end{frame}



\begin{frame}\frametitle{Weighting Matrix}\hypertarget{Weighting Matrix}{}
\begin{itemize}
\item The optimization of the weighting matrix seems to be important to achieve good results for imputation

\item The optimal weighting matrix that minimizes the MSE (not the variance!) is the usual
\[W = \left(E[g(\alpha,\beta; E[y|z])'g(\alpha,\beta; E[y|z])]\right)^{-1}
\]

\item We always going to take the sample analogue of this population moment for our calculations ($\hat{W}$)


\end{itemize}
\end{frame}



\begin{frame}\frametitle{Results}\hypertarget{Results}{}
\begin{itemize}
\item Assume that the estimator $\hat{E}[y|z]$ converges uniformly and the bias is 
$o_p(\sqrt{n}^{-1})$

\item Under usual regulatory assumptions, given that $\hat{W}$ is the sample analogue of $W$,
\begin{enumerate}
\item The imputation estimator is root-n consistent
\item The asymptotic variance-covariance matrix is $(G'WG)^{-1}+o_p(n^{-1/2})$
\item Asymptotically, $MSE=(G'WG)^{-1}$
\item (Asymptotic normality holds - not proven yet)
\end{enumerate}
\begin{itemize}
\item where $G$ is the Jacobian matrix of $g$ w.r.t. the finite dim'l parameters at the true values


\end{itemize}

\end{itemize}
\end{frame}



\begin{frame}\frametitle{Take-away}\hypertarget{Take-away}{}
\begin{itemize}
\item \textbf{Given that the optimal weighting matrix puts non-zero weights on the imputation moments}, the MSE of the imputation estimator is strictly smaller than that of the optimally weighted GMM estimator that discards the observations with missing values

\item When there is no convergent nonparametric estimator for which the bias vanishes fast enough, calculating these additional imputation moments gives more noise to the GMM estimator than they are worth

\item In the Nadaraya-Watson case, we need that the rate of the bandwidth
\[-\frac{1}{k-1}<h<-1/4,
\]  
\begin{itemize}
\item where $k-1$ is the number of non-constant $Z$ elements


\end{itemize}

\end{itemize}
\end{frame}







\section{Monte Carlo simulations}\hypertarget{Monte Carlo simulations}{}


\begin{frame}\frametitle{The data generating process}\hypertarget{The data generating process}{}
\[E[Y|X=x, Z=z]= \Phi(\alpha x + \beta z)
\]
\begin{itemize}
\item The $X$ is a nonlinear function of $Z$ and some exogenous randomness

\item The missingness is based on another probit model and truncation
\[M= \ind[|\gamma z>\epsilon_i|<0.8], \ \epsilon_i\sim N[0,1]
\]
\begin{itemize}
\item this gives missingness rates around 55\%
\end{itemize}

\item We implemented optimal weighting with k=2 ($h=-1/3$)
\item Three estimators: 1. Full-data set GMM (infeasible) 2. Completely-observed GMM 3. Imputation GMM

\end{itemize}
\end{frame}



\begin{frame}\frametitle{Monte Carlo Results (true coefficients are $[1, 0.5, -2]$)}\hypertarget{Monte Carlo Results (true coefficients are $[1, 0.5, -2]$)}{}

\begin{table}
	\begin{tabular}{l|c|c|c}
	$n=4000$ & Full-data & Completely-observed & Imputation \\
\hline
\hline
$\alpha$ & 0.995 & 0.989 & 0.990 \\
& (0.051) & (0.076) & (0.076) \\
\hline
$\beta_0$ & 0.497  & 0.516 & 0.510 \\
& (0.047) & (0.068) & (0.054) \\
\hline
$\beta_1$ & -2.007 & -2.009 & -2.012  \\
& (0.069) & (0.099) & (0.078) \\
\hline
\hline
	$n=16000$ & Full-data & Completely-observed & Imputation \\
\hline
\hline
$\alpha$ & 0.996 & 0.998 & 0.998 \\
& (0.026) & (0.038) & (0.038) \\
\hline
$\beta_0$ & 0.499 & 0.497 & 0.501 \\
& (0.025) & (0.036) & (0.028) \\
\hline
$\beta_1$ & -1.998 & -1.998 & -2.003 \\
& (0.039) & (0.055) & (0.04) \\
\hline
\hline
	\end{tabular}
\end{table}
\end{frame}

\section{Further questions}\hypertarget{Further questions}{}


\begin{frame}\frametitle{More exclusion restrictions, marginalized estimators (speculation)}\hypertarget{More exclusion restrictions}{}
\begin{itemize}
	\item "Simple" imputation is not going to yield better results when the dimension of the $Z$ vector is higher than 4
	\item There are two ways to remedy this
	\begin{enumerate}
		\item getting closer to missing-at random assumptions by adding exclusion restrictions like
		\[M \perp (X, Z_i) | \mathbf{Z_{-i}}
		\]
		\item MAYBE we can devise clever reweighting-schemes to increase the number of moments but decrease the number of variables we condition on in $E[y|z]$ (but the weighting scheme may be just as noisy to calculate, it urns out) 
	\end{enumerate}
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Thank you for your attention}\hypertarget{Thank you for your attention}{}
\end{frame}







\end{document}